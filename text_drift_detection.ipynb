{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "from alibi_detect.cd import LSDDDrift, MMDDrift\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU available')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Uh oh, GPU unavailable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_data() -> pd.DataFrame:\n",
    "    biden_first: list[tuple[any, str]] = pickle.load(open(\"biden_first_half.pickle\", 'rb'))\n",
    "    biden_last = pickle.load(open(\"biden_last_half.pickle\", 'rb'))\n",
    "    biden_first.extend(biden_last)\n",
    "    return pd.DataFrame(biden_first, columns=[\"datetime\", \"tweet\"])\n",
    "\n",
    "biden_df = assemble_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 00:00:20</td>\n",
       "      <td>@IslandGirlPRV @BradBeauregardJ @MeidasTouch T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-15 00:00:21</td>\n",
       "      <td>@chrislongview Watching and setting dvr. Lets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 00:00:22</td>\n",
       "      <td>#censorship #HunterBiden #Biden #BidenEmails #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-15 00:00:23</td>\n",
       "      <td>\"IS THIS WRONG??!!\" Cory Booker's BRILLIANT Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 00:00:25</td>\n",
       "      <td>In 2020, #NYPost is being #censorship #CENSORE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521116</th>\n",
       "      <td>2020-11-08 23:59:16</td>\n",
       "      <td>Mr. #Biden, tear down that wall (with #Mexico)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521117</th>\n",
       "      <td>2020-11-08 23:59:32</td>\n",
       "      <td>NYT: #BeratAlbayraks departure may also signal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521118</th>\n",
       "      <td>2020-11-08 23:59:33</td>\n",
       "      <td>@staceyabrams Thank you for all your support a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521119</th>\n",
       "      <td>2020-11-08 23:59:34</td>\n",
       "      <td>@elnuevoherald LOS MEDIOS A LA FUERZA QUIEREN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521120</th>\n",
       "      <td>2020-11-08 23:59:38</td>\n",
       "      <td>Stop laying @CNN ! #Paris and #London dont giv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>521121 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime                                              tweet\n",
       "0      2020-10-15 00:00:20  @IslandGirlPRV @BradBeauregardJ @MeidasTouch T...\n",
       "1      2020-10-15 00:00:21  @chrislongview Watching and setting dvr. Lets ...\n",
       "2      2020-10-15 00:00:22  #censorship #HunterBiden #Biden #BidenEmails #...\n",
       "3      2020-10-15 00:00:23  \"IS THIS WRONG??!!\" Cory Booker's BRILLIANT Fi...\n",
       "4      2020-10-15 00:00:25  In 2020, #NYPost is being #censorship #CENSORE...\n",
       "...                    ...                                                ...\n",
       "521116 2020-11-08 23:59:16  Mr. #Biden, tear down that wall (with #Mexico)...\n",
       "521117 2020-11-08 23:59:32  NYT: #BeratAlbayraks departure may also signal...\n",
       "521118 2020-11-08 23:59:33  @staceyabrams Thank you for all your support a...\n",
       "521119 2020-11-08 23:59:34  @elnuevoherald LOS MEDIOS A LA FUERZA QUIEREN ...\n",
       "521120 2020-11-08 23:59:38  Stop laying @CNN ! #Paris and #London dont giv...\n",
       "\n",
       "[521121 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_debate_date = \"2020-10-23\"\n",
    "post_election_date = \"2020-11-04\"\n",
    "biden_pre_debate = biden_df[biden_df[\"datetime\"] < post_debate_date]\n",
    "biden_post_debate = biden_df[(biden_df[\"datetime\"] >= post_debate_date) & (biden_df[\"datetime\"] < post_election_date)]\n",
    "biden_post_election = biden_df[biden_df[\"datetime\"] >= post_election_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py312/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(model_checkpoint)\n",
    "model = transformers.BertModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "model.train()\n",
    "model.to(device)\n",
    "pre_debate_null = tokenizer(biden_pre_debate[\"tweet\"].sample(n).tolist(), padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   101,    108,  40315,  ...,      0,      0,      0],\n",
       "        [   101,    137,  14309,  ...,      0,      0,      0],\n",
       "        [   101,  46361,  66058,  ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [   101,    137, 103306,  ...,      0,      0,      0],\n",
       "        [   101,    137,  10734,  ...,      0,      0,      0],\n",
       "        [   101,    137,  13486,  ...,      0,      0,      0]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_debate_null['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pre_debate_null_embeddings = model.forward(**pre_debate_null, output_hidden_states=False)#.last_hidden_state[:, 0, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3055, -0.0568,  0.2168,  ..., -0.2143, -0.0010,  0.1692],\n",
       "        [ 0.1602, -0.1356,  0.3190,  ..., -0.2114,  0.1897,  0.1591],\n",
       "        [ 0.1960, -0.1599,  0.2846,  ..., -0.0137,  0.2131,  0.1596],\n",
       "        ...,\n",
       "        [ 0.0953, -0.2176,  0.4431,  ..., -0.3339,  0.3082,  0.1643],\n",
       "        [ 0.4526, -0.1542,  0.3967,  ..., -0.4728,  0.2763,  0.2856],\n",
       "        [ 0.1688, -0.0469,  0.2878,  ..., -0.2344,  0.1260,  0.0599]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pre_debate_null_embeddings.pooler_output.shape)\n",
    "pre_debate_null_embeddings.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0221, -0.0602, -0.3180,  ...,  0.2246,  0.2059, -0.3551],\n",
       "        [ 0.0234, -0.1797, -0.0762,  ...,  0.0375,  0.1536, -0.1373],\n",
       "        [-0.2330, -0.3120, -0.0973,  ...,  0.2119,  0.1197, -0.2244],\n",
       "        ...,\n",
       "        [-0.1456, -0.0919, -0.3073,  ...,  0.1412,  0.1634, -0.1895],\n",
       "        [-0.2168,  0.1021, -0.1197,  ...,  0.5530,  0.1545, -0.0289],\n",
       "        [ 0.0633, -0.4306, -0.0654,  ...,  0.2322, -0.1206, -0.0192]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pre_debate_null_embeddings.last_hidden_state[:, 0, :].shape)\n",
    "pre_debate_null_embeddings.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3536910336\n"
     ]
    }
   ],
   "source": [
    "del pre_debate_null_embeddings\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/anaconda/envs/py312/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/py312/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/py312/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/py312/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "n = 1000\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "for i in range(n_epochs):\n",
    "    pre_debate_null = tokenizer(biden_pre_debate[\"tweet\"].sample(n).tolist(), padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "    print(torch.cuda.memory_allocated())\n",
    "    #pre_debate_null_embeddings = model(**pre_debate_null).last_hidden_state[:, 0, :].cpu().detach().numpy()\n",
    "    del pre_debate_null\n",
    "    \n",
    "    pre_debate = tokenizer(biden_pre_debate[\"tweet\"].sample(n).tolist(), padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "    pre_debate_embeddings = model(**pre_debate).last_hidden_state[:, 0, :].cpu().detach().numpy()\n",
    "    del pre_debate\n",
    "    \n",
    "    post_debate = tokenizer(biden_post_debate[\"tweet\"].sample(n).tolist(), padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "    post_debate_embeddings = model(**post_debate).last_hidden_state[:, 0, :].cpu().detach().numpy()\n",
    "    del post_debate\n",
    "    \n",
    "    post_election = tokenizer(biden_post_election[\"tweet\"].sample(n).tolist(), padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
    "    post_election_embeddings = model(**post_election).last_hidden_state[:, 0, :].cpu().detach().numpy()\n",
    "    del post_election\n",
    "\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    mmddrift = MMDDrift(x_ref=pre_debate_null_embeddings, backend=\"pytorch\", p_val=.05)\n",
    "    lsdddrift = LSDDDrift(x_ref=pre_debate_null_embeddings, backend=\"pytorch\", p_val=.05)\n",
    "\n",
    "    #mmddrift.predict(pre_debate_null_embeddings)\n",
    "    mmddrift.predict(pre_debate_embeddings)\n",
    "    mmddrift.predict(post_debate_embeddings)\n",
    "    mmddrift.predict(post_election_embeddings)\n",
    "\n",
    "    #lsdddrift.predict(pre_debate_null_embeddings)\n",
    "    lsdddrift.predict(pre_debate_embeddings)\n",
    "    lsdddrift.predict(post_debate_embeddings)\n",
    "    lsdddrift.predict(post_election_embeddings)\n",
    "\n",
    "    del pre_debate_null_embeddings, pre_debate_embeddings, post_debate_embeddings, post_election_embeddings\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
